{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCM/Bv31PGHM8ovPiGMzF2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/telnarayanan/HuggingFaceTransformers/blob/main/1_TransfomerModels_Transformers_Architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Transfer Learning\n",
        "    * Trained models are usually trained with large amounts of data.\n",
        "    * In these large models, the weights are usually shared along with the model.\n",
        "    * So instead of training from scratch, we can begin from the pre-trained weights, and start fine tuning the model.\n",
        "    * Sometimes pretrained models also come with inherent biases.\n",
        "    * To perform fine-tuning, you first acquire a pre-trained language model, then perform additional training with dataset specific to your task.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tJyKD_1OZ2Wo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Transformer Architectures\n",
        "    * Encoders\n",
        "    * Decoders\n",
        "    * Encoder-Decoder Mechanism\n",
        "\n",
        "* Encoder\n",
        "    * Self-attention\n",
        "    * Bi-directional properties\n",
        "\n",
        "* Decoder\n",
        "    * Masked Self-attention\n",
        "    * Uni-Directional\n",
        "    * Auto-regressive\n",
        "\n",
        "* Encoder-Decoder or Sequence to Sequence Transformer"
      ],
      "metadata": {
        "id": "8FEE4fhIbSKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Archicture\n",
        "    * The skeleton of the model. The definition of each layer and each operation that happens within the model.\n",
        "\n",
        "* CheckPoints    \n",
        "    * These are the weights that will be loaded into the architecture\n",
        "\n",
        "* Model\n",
        "    * This is an umbrella term, that isn't as precise as 'architecture' or 'checkpoint'; It could refer both\n"
      ],
      "metadata": {
        "id": "nLy_xTNyb87o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Encoder Models\n",
        "    * Encoder only architecture - BERT\n",
        "    * Converts input work into feature tensor, or feature vector\n",
        "\n",
        "* Self-Attention\n",
        "    * Each word in the initial seq, affects every word's representation\n",
        "    * Representation of different words get affected by the presence of other words in the sequence.\n",
        "\n",
        "* Encoder\n",
        "    * Masked Language Modelling\n",
        "     "
      ],
      "metadata": {
        "id": "8oYmzvhTdBiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Decoder Architecture\n",
        "    * Eg. GPT, GPT 2\n",
        "    * Masked Self attention (Words on the rights are masked from the context. It hides the context)\n",
        "    * Useful in Language Generation"
      ],
      "metadata": {
        "id": "8h1eGUSqecTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Sequence to Sequence Architecture / Encoder-Decoder Architecture\n",
        "    * Eg. T5 models.\n",
        "    * BART - (Autoregessive - Output of Encoder is the Input of Decoder)\n"
      ],
      "metadata": {
        "id": "KUNKezcZfdr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcXJutm7gJqp",
        "outputId": "388577aa-b163-4613-a93e-6f33e869c7e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 32.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 39.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "\n",
        "# unmasker(\"This guy works as a [MASK]\", top_k=5)\n",
        "print([unmasker(\"This man works as a  <mask>\", top_k=5)])\n",
        "print([unmasker(\"This guy works as a  <mask>\", top_k=5)])\n",
        "print([unmasker(\"This chap works as a  <mask>\", top_k=5)])\n",
        "print([unmasker(\"This lady works as a  <mask>\", top_k=5)])\n",
        "print([unmasker(\"This gentleman works as a  <mask>\", top_k=5)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as-dWP-2gQ6c",
        "outputId": "b3f48c04-fffe-4304-acca-a0c8ae757277"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'score': 0.08593586087226868, 'token': 37171, 'token_str': ' courier', 'sequence': 'This man works as a courier'}, {'score': 0.0826975628733635, 'token': 28894, 'token_str': ' translator', 'sequence': 'This man works as a translator'}, {'score': 0.05225104093551636, 'token': 38233, 'token_str': ' waiter', 'sequence': 'This man works as a waiter'}, {'score': 0.051457200199365616, 'token': 8298, 'token_str': ' consultant', 'sequence': 'This man works as a consultant'}, {'score': 0.037423133850097656, 'token': 33080, 'token_str': ' bartender', 'sequence': 'This man works as a bartender'}]]\n",
            "[[{'score': 0.0895586684346199, 'token': 33080, 'token_str': ' bartender', 'sequence': 'This guy works as a bartender'}, {'score': 0.060309410095214844, 'token': 38233, 'token_str': ' waiter', 'sequence': 'This guy works as a waiter'}, {'score': 0.051569584757089615, 'token': 28894, 'token_str': ' translator', 'sequence': 'This guy works as a translator'}, {'score': 0.0494999997317791, 'token': 8298, 'token_str': ' consultant', 'sequence': 'This guy works as a consultant'}, {'score': 0.031857509166002274, 'token': 37171, 'token_str': ' courier', 'sequence': 'This guy works as a courier'}]]\n",
            "[[{'score': 0.2625865638256073, 'token': 28894, 'token_str': ' translator', 'sequence': 'This chap works as a translator'}, {'score': 0.03239947184920311, 'token': 10268, 'token_str': ' substitute', 'sequence': 'This chap works as a substitute'}, {'score': 0.031165458261966705, 'token': 38296, 'token_str': ' tutor', 'sequence': 'This chap works as a tutor'}, {'score': 0.017698826268315315, 'token': 34697, 'token_str': ' messenger', 'sequence': 'This chap works as a messenger'}, {'score': 0.013210727833211422, 'token': 8298, 'token_str': ' consultant', 'sequence': 'This chap works as a consultant'}]]\n",
            "[[{'score': 0.1278694123029709, 'token': 35698, 'token_str': ' waitress', 'sequence': 'This lady works as a waitress'}, {'score': 0.08787816762924194, 'token': 28894, 'token_str': ' translator', 'sequence': 'This lady works as a translator'}, {'score': 0.07389914244413376, 'token': 38233, 'token_str': ' waiter', 'sequence': 'This lady works as a waiter'}, {'score': 0.07004173845052719, 'token': 33080, 'token_str': ' bartender', 'sequence': 'This lady works as a bartender'}, {'score': 0.04753514751791954, 'token': 37171, 'token_str': ' courier', 'sequence': 'This lady works as a courier'}]]\n",
            "[[{'score': 0.1228303611278534, 'token': 38233, 'token_str': ' waiter', 'sequence': 'This gentleman works as a waiter'}, {'score': 0.09362673759460449, 'token': 33080, 'token_str': ' bartender', 'sequence': 'This gentleman works as a bartender'}, {'score': 0.05653352290391922, 'token': 37171, 'token_str': ' courier', 'sequence': 'This gentleman works as a courier'}, {'score': 0.05615143105387688, 'token': 28894, 'token_str': ' translator', 'sequence': 'This gentleman works as a translator'}, {'score': 0.025017790496349335, 'token': 8298, 'token_str': ' consultant', 'sequence': 'This gentleman works as a consultant'}]]\n"
          ]
        }
      ]
    }
  ]
}